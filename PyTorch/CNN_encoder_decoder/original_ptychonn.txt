GPUs: 1 Batch size: 64 Learning rate: 0.001
/gpfs/mira-home/mansisak/PtychoNN/data/20191008_39_diff.npz
(161, 161, 64, 64)
(161, 161, 256, 256)
101
(16100, 1, 64, 64)
3.1268637 -1.564053
x_train tensor, y_i train tensor, y_phi train tensor
torch.Size([16100, 1, 64, 64]) torch.Size([16100, 1, 64, 64]) torch.Size([16100, 1, 64, 64])
15295 805
batch size: torch.Size([64, 1, 64, 64])
torch.Size([64, 1, 64, 64]) torch.Size([64, 1, 64, 64])
torch.float32 torch.float32
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 64, 64]             320
              ReLU-2           [-1, 32, 64, 64]               0
            Conv2d-3           [-1, 32, 64, 64]           9,248
              ReLU-4           [-1, 32, 64, 64]               0
         MaxPool2d-5           [-1, 32, 32, 32]               0
            Conv2d-6           [-1, 64, 32, 32]          18,496
              ReLU-7           [-1, 64, 32, 32]               0
            Conv2d-8           [-1, 64, 32, 32]          36,928
              ReLU-9           [-1, 64, 32, 32]               0
        MaxPool2d-10           [-1, 64, 16, 16]               0
           Conv2d-11          [-1, 128, 16, 16]          73,856
             ReLU-12          [-1, 128, 16, 16]               0
           Conv2d-13          [-1, 128, 16, 16]         147,584
             ReLU-14          [-1, 128, 16, 16]               0
        MaxPool2d-15            [-1, 128, 8, 8]               0
           Conv2d-16            [-1, 128, 8, 8]         147,584
             ReLU-17            [-1, 128, 8, 8]               0
           Conv2d-18            [-1, 128, 8, 8]         147,584
             ReLU-19            [-1, 128, 8, 8]               0
         Upsample-20          [-1, 128, 16, 16]               0
           Conv2d-21           [-1, 64, 16, 16]          73,792
             ReLU-22           [-1, 64, 16, 16]               0
           Conv2d-23           [-1, 64, 16, 16]          36,928
             ReLU-24           [-1, 64, 16, 16]               0
         Upsample-25           [-1, 64, 32, 32]               0
           Conv2d-26           [-1, 64, 32, 32]          36,928
             ReLU-27           [-1, 64, 32, 32]               0
           Conv2d-28           [-1, 64, 32, 32]          36,928
             ReLU-29           [-1, 64, 32, 32]               0
         Upsample-30           [-1, 64, 64, 64]               0
           Conv2d-31            [-1, 1, 64, 64]             577
          Sigmoid-32            [-1, 1, 64, 64]               0
           Conv2d-33            [-1, 128, 8, 8]         147,584
             ReLU-34            [-1, 128, 8, 8]               0
           Conv2d-35            [-1, 128, 8, 8]         147,584
             ReLU-36            [-1, 128, 8, 8]               0
         Upsample-37          [-1, 128, 16, 16]               0
           Conv2d-38           [-1, 64, 16, 16]          73,792
             ReLU-39           [-1, 64, 16, 16]               0
           Conv2d-40           [-1, 64, 16, 16]          36,928
             ReLU-41           [-1, 64, 16, 16]               0
         Upsample-42           [-1, 64, 32, 32]               0
           Conv2d-43           [-1, 64, 32, 32]          36,928
             ReLU-44           [-1, 64, 32, 32]               0
           Conv2d-45           [-1, 64, 32, 32]          36,928
             ReLU-46           [-1, 64, 32, 32]               0
         Upsample-47           [-1, 64, 64, 64]               0
           Conv2d-48            [-1, 1, 64, 64]             577
             Tanh-49            [-1, 1, 64, 64]               0
================================================================
Total params: 1,247,074
Trainable params: 1,247,074
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 18.56
Params size (MB): 4.76
Estimated Total Size (MB): 23.34
----------------------------------------------------------------
LR step size is: 1434.0 which is every 6 epochs
Saving improved model after Val Loss improved from inf to 0.66876
Epoch: 0 | FT  | Train Loss: 0.73348 | Val Loss: 0.66876
Epoch: 0 | Amp | Train Loss: 0.0725 | Val Loss: 0.0170
Epoch: 0 | Ph  | Train Loss: 0.661 | Val Loss: 0.652
Epoch: 0 | Ending LR: 0.000250 
Saving improved model after Val Loss improved from 0.66876 to 0.56716
Epoch: 1 | FT  | Train Loss: 0.56049 | Val Loss: 0.56716
Epoch: 1 | Amp | Train Loss: 0.0195 | Val Loss: 0.0140
Epoch: 1 | Ph  | Train Loss: 0.541 | Val Loss: 0.553
Epoch: 1 | Ending LR: 0.000400 
Saving improved model after Val Loss improved from 0.56716 to 0.49372
Epoch: 2 | FT  | Train Loss: 0.45434 | Val Loss: 0.49372
Epoch: 2 | Amp | Train Loss: 0.0143 | Val Loss: 0.0459
Epoch: 2 | Ph  | Train Loss: 0.440 | Val Loss: 0.448
Epoch: 2 | Ending LR: 0.000550 
Saving improved model after Val Loss improved from 0.49372 to 0.39792
Epoch: 3 | FT  | Train Loss: 0.38844 | Val Loss: 0.39792
Epoch: 3 | Amp | Train Loss: 0.0154 | Val Loss: 0.0140
Epoch: 3 | Ph  | Train Loss: 0.373 | Val Loss: 0.384
Epoch: 3 | Ending LR: 0.000700 
Saving improved model after Val Loss improved from 0.39792 to 0.36239
Epoch: 4 | FT  | Train Loss: 0.34463 | Val Loss: 0.36239
Epoch: 4 | Amp | Train Loss: 0.0124 | Val Loss: 0.0101
Epoch: 4 | Ph  | Train Loss: 0.332 | Val Loss: 0.352
Epoch: 4 | Ending LR: 0.000850 
Saving improved model after Val Loss improved from 0.36239 to 0.33116
Epoch: 5 | FT  | Train Loss: 0.31568 | Val Loss: 0.33116
Epoch: 5 | Amp | Train Loss: 0.0095 | Val Loss: 0.0080
Epoch: 5 | Ph  | Train Loss: 0.306 | Val Loss: 0.323
Epoch: 5 | Ending LR: 0.001000 
Saving improved model after Val Loss improved from 0.33116 to 0.31201
Epoch: 6 | FT  | Train Loss: 0.28366 | Val Loss: 0.31201
Epoch: 6 | Amp | Train Loss: 0.0069 | Val Loss: 0.0070
Epoch: 6 | Ph  | Train Loss: 0.277 | Val Loss: 0.305
Epoch: 6 | Ending LR: 0.000850 
Saving improved model after Val Loss improved from 0.31201 to 0.27019
Epoch: 7 | FT  | Train Loss: 0.25065 | Val Loss: 0.27019
Epoch: 7 | Amp | Train Loss: 0.0063 | Val Loss: 0.0068
Epoch: 7 | Ph  | Train Loss: 0.244 | Val Loss: 0.263
Epoch: 7 | Ending LR: 0.000700 
Saving improved model after Val Loss improved from 0.27019 to 0.24615
Epoch: 8 | FT  | Train Loss: 0.22269 | Val Loss: 0.24615
Epoch: 8 | Amp | Train Loss: 0.0062 | Val Loss: 0.0066
Epoch: 8 | Ph  | Train Loss: 0.217 | Val Loss: 0.240
Epoch: 8 | Ending LR: 0.000550 
Saving improved model after Val Loss improved from 0.24615 to 0.22340
Epoch: 9 | FT  | Train Loss: 0.19713 | Val Loss: 0.22340
Epoch: 9 | Amp | Train Loss: 0.0060 | Val Loss: 0.0065
Epoch: 9 | Ph  | Train Loss: 0.191 | Val Loss: 0.217
Epoch: 9 | Ending LR: 0.000400 
Saving improved model after Val Loss improved from 0.22340 to 0.20526
Epoch: 10 | FT  | Train Loss: 0.17521 | Val Loss: 0.20526
Epoch: 10 | Amp | Train Loss: 0.0059 | Val Loss: 0.0064
Epoch: 10 | Ph  | Train Loss: 0.169 | Val Loss: 0.199
Epoch: 10 | Ending LR: 0.000250 
Saving improved model after Val Loss improved from 0.20526 to 0.19207
Epoch: 11 | FT  | Train Loss: 0.15640 | Val Loss: 0.19207
Epoch: 11 | Amp | Train Loss: 0.0058 | Val Loss: 0.0063
Epoch: 11 | Ph  | Train Loss: 0.151 | Val Loss: 0.186
Epoch: 11 | Ending LR: 0.000100 
Saving improved model after Val Loss improved from 0.19207 to 0.19026
Epoch: 12 | FT  | Train Loss: 0.14680 | Val Loss: 0.19026
Epoch: 12 | Amp | Train Loss: 0.0058 | Val Loss: 0.0063
Epoch: 12 | Ph  | Train Loss: 0.141 | Val Loss: 0.184
Epoch: 12 | Ending LR: 0.000175 
Epoch: 13 | FT  | Train Loss: 0.14770 | Val Loss: 0.19199
Epoch: 13 | Amp | Train Loss: 0.0058 | Val Loss: 0.0063
Epoch: 13 | Ph  | Train Loss: 0.142 | Val Loss: 0.186
Epoch: 13 | Ending LR: 0.000250 
Epoch: 14 | FT  | Train Loss: 0.15216 | Val Loss: 0.19763
Epoch: 14 | Amp | Train Loss: 0.0058 | Val Loss: 0.0062
Epoch: 14 | Ph  | Train Loss: 0.146 | Val Loss: 0.191
Epoch: 14 | Ending LR: 0.000325 
Epoch: 15 | FT  | Train Loss: 0.15762 | Val Loss: 0.19919
Epoch: 15 | Amp | Train Loss: 0.0057 | Val Loss: 0.0062
Epoch: 15 | Ph  | Train Loss: 0.152 | Val Loss: 0.193
Epoch: 15 | Ending LR: 0.000400 
Epoch: 16 | FT  | Train Loss: 0.16228 | Val Loss: 0.20541
Epoch: 16 | Amp | Train Loss: 0.0057 | Val Loss: 0.0062
Epoch: 16 | Ph  | Train Loss: 0.157 | Val Loss: 0.199
Epoch: 16 | Ending LR: 0.000475 
Epoch: 17 | FT  | Train Loss: 0.16620 | Val Loss: 0.20475
Epoch: 17 | Amp | Train Loss: 0.0057 | Val Loss: 0.0063
Epoch: 17 | Ph  | Train Loss: 0.160 | Val Loss: 0.198
Epoch: 17 | Ending LR: 0.000550 
Epoch: 18 | FT  | Train Loss: 0.16242 | Val Loss: 0.19042
Epoch: 18 | Amp | Train Loss: 0.0056 | Val Loss: 0.0061
Epoch: 18 | Ph  | Train Loss: 0.157 | Val Loss: 0.184
Epoch: 18 | Ending LR: 0.000475 
Saving improved model after Val Loss improved from 0.19026 to 0.18048
Epoch: 19 | FT  | Train Loss: 0.14848 | Val Loss: 0.18048
Epoch: 19 | Amp | Train Loss: 0.0055 | Val Loss: 0.0060
Epoch: 19 | Ph  | Train Loss: 0.143 | Val Loss: 0.175
Epoch: 19 | Ending LR: 0.000400 
Saving improved model after Val Loss improved from 0.18048 to 0.17079
Epoch: 20 | FT  | Train Loss: 0.13604 | Val Loss: 0.17079
Epoch: 20 | Amp | Train Loss: 0.0053 | Val Loss: 0.0058
Epoch: 20 | Ph  | Train Loss: 0.131 | Val Loss: 0.165
Epoch: 20 | Ending LR: 0.000325 
Saving improved model after Val Loss improved from 0.17079 to 0.16065
Epoch: 21 | FT  | Train Loss: 0.12553 | Val Loss: 0.16065
Epoch: 21 | Amp | Train Loss: 0.0052 | Val Loss: 0.0057
Epoch: 21 | Ph  | Train Loss: 0.120 | Val Loss: 0.155
Epoch: 21 | Ending LR: 0.000250 
Saving improved model after Val Loss improved from 0.16065 to 0.15562
Epoch: 22 | FT  | Train Loss: 0.11578 | Val Loss: 0.15562
Epoch: 22 | Amp | Train Loss: 0.0050 | Val Loss: 0.0056
Epoch: 22 | Ph  | Train Loss: 0.111 | Val Loss: 0.150
Epoch: 22 | Ending LR: 0.000175 
Saving improved model after Val Loss improved from 0.15562 to 0.14936
Epoch: 23 | FT  | Train Loss: 0.10756 | Val Loss: 0.14936
Epoch: 23 | Amp | Train Loss: 0.0049 | Val Loss: 0.0055
Epoch: 23 | Ph  | Train Loss: 0.103 | Val Loss: 0.144
Epoch: 23 | Ending LR: 0.000100 
Saving improved model after Val Loss improved from 0.14936 to 0.14934
Epoch: 24 | FT  | Train Loss: 0.10300 | Val Loss: 0.14934
Epoch: 24 | Amp | Train Loss: 0.0049 | Val Loss: 0.0055
Epoch: 24 | Ph  | Train Loss: 0.098 | Val Loss: 0.144
Epoch: 24 | Ending LR: 0.000138 
Epoch: 25 | FT  | Train Loss: 0.10368 | Val Loss: 0.15176
Epoch: 25 | Amp | Train Loss: 0.0048 | Val Loss: 0.0055
Epoch: 25 | Ph  | Train Loss: 0.099 | Val Loss: 0.146
Epoch: 25 | Ending LR: 0.000175 
Epoch: 26 | FT  | Train Loss: 0.10620 | Val Loss: 0.15276
Epoch: 26 | Amp | Train Loss: 0.0048 | Val Loss: 0.0055
Epoch: 26 | Ph  | Train Loss: 0.101 | Val Loss: 0.147
Epoch: 26 | Ending LR: 0.000213 
Epoch: 27 | FT  | Train Loss: 0.10938 | Val Loss: 0.15763
Epoch: 27 | Amp | Train Loss: 0.0048 | Val Loss: 0.0055
Epoch: 27 | Ph  | Train Loss: 0.105 | Val Loss: 0.152
Epoch: 27 | Ending LR: 0.000250 
Epoch: 28 | FT  | Train Loss: 0.11367 | Val Loss: 0.15951
Epoch: 28 | Amp | Train Loss: 0.0048 | Val Loss: 0.0055
Epoch: 28 | Ph  | Train Loss: 0.109 | Val Loss: 0.154
Epoch: 28 | Ending LR: 0.000287 
Epoch: 29 | FT  | Train Loss: 0.11734 | Val Loss: 0.15888
Epoch: 29 | Amp | Train Loss: 0.0048 | Val Loss: 0.0054
Epoch: 29 | Ph  | Train Loss: 0.113 | Val Loss: 0.153
Epoch: 29 | Ending LR: 0.000325 
Epoch: 30 | FT  | Train Loss: 0.11700 | Val Loss: 0.15494
Epoch: 30 | Amp | Train Loss: 0.0048 | Val Loss: 0.0054
Epoch: 30 | Ph  | Train Loss: 0.112 | Val Loss: 0.150
Epoch: 30 | Ending LR: 0.000287 
Epoch: 31 | FT  | Train Loss: 0.11058 | Val Loss: 0.15219
Epoch: 31 | Amp | Train Loss: 0.0046 | Val Loss: 0.0053
Epoch: 31 | Ph  | Train Loss: 0.106 | Val Loss: 0.147
Epoch: 31 | Ending LR: 0.000250 
Saving improved model after Val Loss improved from 0.14934 to 0.14539
Epoch: 32 | FT  | Train Loss: 0.10358 | Val Loss: 0.14539
Epoch: 32 | Amp | Train Loss: 0.0045 | Val Loss: 0.0052
Epoch: 32 | Ph  | Train Loss: 0.099 | Val Loss: 0.140
Epoch: 32 | Ending LR: 0.000213 
Saving improved model after Val Loss improved from 0.14539 to 0.14193
Epoch: 33 | FT  | Train Loss: 0.09825 | Val Loss: 0.14193
Epoch: 33 | Amp | Train Loss: 0.0044 | Val Loss: 0.0052
Epoch: 33 | Ph  | Train Loss: 0.094 | Val Loss: 0.137
Epoch: 33 | Ending LR: 0.000175 
Saving improved model after Val Loss improved from 0.14193 to 0.13894
Epoch: 34 | FT  | Train Loss: 0.09302 | Val Loss: 0.13894
Epoch: 34 | Amp | Train Loss: 0.0043 | Val Loss: 0.0051
Epoch: 34 | Ph  | Train Loss: 0.089 | Val Loss: 0.134
Epoch: 34 | Ending LR: 0.000138 
Saving improved model after Val Loss improved from 0.13894 to 0.13638
Epoch: 35 | FT  | Train Loss: 0.08860 | Val Loss: 0.13638
Epoch: 35 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051
Epoch: 35 | Ph  | Train Loss: 0.084 | Val Loss: 0.131
Epoch: 35 | Ending LR: 0.000100 
Saving improved model after Val Loss improved from 0.13638 to 0.13622
Epoch: 36 | FT  | Train Loss: 0.08627 | Val Loss: 0.13622
Epoch: 36 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051
Epoch: 36 | Ph  | Train Loss: 0.082 | Val Loss: 0.131
Epoch: 36 | Ending LR: 0.000119 
Epoch: 37 | FT  | Train Loss: 0.08678 | Val Loss: 0.13797
Epoch: 37 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051
Epoch: 37 | Ph  | Train Loss: 0.083 | Val Loss: 0.133
Epoch: 37 | Ending LR: 0.000137 
Epoch: 38 | FT  | Train Loss: 0.08832 | Val Loss: 0.13857
Epoch: 38 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051
Epoch: 38 | Ph  | Train Loss: 0.084 | Val Loss: 0.134
Epoch: 38 | Ending LR: 0.000156 
Epoch: 39 | FT  | Train Loss: 0.09015 | Val Loss: 0.14101
Epoch: 39 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051
Epoch: 39 | Ph  | Train Loss: 0.086 | Val Loss: 0.136
Epoch: 39 | Ending LR: 0.000175 
Epoch: 40 | FT  | Train Loss: 0.09214 | Val Loss: 0.14034
Epoch: 40 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051
Epoch: 40 | Ph  | Train Loss: 0.088 | Val Loss: 0.135
Epoch: 40 | Ending LR: 0.000194 
Epoch: 41 | FT  | Train Loss: 0.09396 | Val Loss: 0.14118
Epoch: 41 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051
Epoch: 41 | Ph  | Train Loss: 0.090 | Val Loss: 0.136
Epoch: 41 | Ending LR: 0.000213 
Epoch: 42 | FT  | Train Loss: 0.09399 | Val Loss: 0.14008
Epoch: 42 | Amp | Train Loss: 0.0042 | Val Loss: 0.0050
Epoch: 42 | Ph  | Train Loss: 0.090 | Val Loss: 0.135
Epoch: 42 | Ending LR: 0.000194 
Epoch: 43 | FT  | Train Loss: 0.09070 | Val Loss: 0.13764
Epoch: 43 | Amp | Train Loss: 0.0041 | Val Loss: 0.0050
Epoch: 43 | Ph  | Train Loss: 0.087 | Val Loss: 0.133
Epoch: 43 | Ending LR: 0.000175 
Saving improved model after Val Loss improved from 0.13622 to 0.13605
Epoch: 44 | FT  | Train Loss: 0.08719 | Val Loss: 0.13605
Epoch: 44 | Amp | Train Loss: 0.0040 | Val Loss: 0.0049
Epoch: 44 | Ph  | Train Loss: 0.083 | Val Loss: 0.131
Epoch: 44 | Ending LR: 0.000156 
Saving improved model after Val Loss improved from 0.13605 to 0.13365
Epoch: 45 | FT  | Train Loss: 0.08429 | Val Loss: 0.13365
Epoch: 45 | Amp | Train Loss: 0.0040 | Val Loss: 0.0049
Epoch: 45 | Ph  | Train Loss: 0.080 | Val Loss: 0.129
Epoch: 45 | Ending LR: 0.000137 
Saving improved model after Val Loss improved from 0.13365 to 0.13233
Epoch: 46 | FT  | Train Loss: 0.08160 | Val Loss: 0.13233
Epoch: 46 | Amp | Train Loss: 0.0039 | Val Loss: 0.0049
Epoch: 46 | Ph  | Train Loss: 0.078 | Val Loss: 0.127
Epoch: 46 | Ending LR: 0.000119 
Saving improved model after Val Loss improved from 0.13233 to 0.13154
Epoch: 47 | FT  | Train Loss: 0.07916 | Val Loss: 0.13154
Epoch: 47 | Amp | Train Loss: 0.0038 | Val Loss: 0.0048
Epoch: 47 | Ph  | Train Loss: 0.075 | Val Loss: 0.127
Epoch: 47 | Ending LR: 0.000100 
Epoch: 48 | FT  | Train Loss: 0.07786 | Val Loss: 0.13204
Epoch: 48 | Amp | Train Loss: 0.0038 | Val Loss: 0.0048
Epoch: 48 | Ph  | Train Loss: 0.074 | Val Loss: 0.127
Epoch: 48 | Ending LR: 0.000109 
Saving improved model after Val Loss improved from 0.13154 to 0.13145
Epoch: 49 | FT  | Train Loss: 0.07828 | Val Loss: 0.13145
Epoch: 49 | Amp | Train Loss: 0.0038 | Val Loss: 0.0048
Epoch: 49 | Ph  | Train Loss: 0.074 | Val Loss: 0.127
Epoch: 49 | Ending LR: 0.000119 
Epoch: 50 | FT  | Train Loss: 0.07896 | Val Loss: 0.13197
Epoch: 50 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049
Epoch: 50 | Ph  | Train Loss: 0.075 | Val Loss: 0.127
Epoch: 50 | Ending LR: 0.000128 
Epoch: 51 | FT  | Train Loss: 0.07982 | Val Loss: 0.13397
Epoch: 51 | Amp | Train Loss: 0.0038 | Val Loss: 0.0048
Epoch: 51 | Ph  | Train Loss: 0.076 | Val Loss: 0.129
Epoch: 51 | Ending LR: 0.000137 
Epoch: 52 | FT  | Train Loss: 0.08155 | Val Loss: 0.13312
Epoch: 52 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049
Epoch: 52 | Ph  | Train Loss: 0.078 | Val Loss: 0.128
Epoch: 52 | Ending LR: 0.000147 
Epoch: 53 | FT  | Train Loss: 0.08199 | Val Loss: 0.13386
Epoch: 53 | Amp | Train Loss: 0.0038 | Val Loss: 0.0048
Epoch: 53 | Ph  | Train Loss: 0.078 | Val Loss: 0.129
Epoch: 53 | Ending LR: 0.000156 
Epoch: 54 | FT  | Train Loss: 0.08161 | Val Loss: 0.13315
Epoch: 54 | Amp | Train Loss: 0.0038 | Val Loss: 0.0048
Epoch: 54 | Ph  | Train Loss: 0.078 | Val Loss: 0.128
Epoch: 54 | Ending LR: 0.000147 
Epoch: 55 | FT  | Train Loss: 0.07998 | Val Loss: 0.13189
Epoch: 55 | Amp | Train Loss: 0.0038 | Val Loss: 0.0048
Epoch: 55 | Ph  | Train Loss: 0.076 | Val Loss: 0.127
Epoch: 55 | Ending LR: 0.000137 
Epoch: 56 | FT  | Train Loss: 0.07825 | Val Loss: 0.13166
Epoch: 56 | Amp | Train Loss: 0.0037 | Val Loss: 0.0048
Epoch: 56 | Ph  | Train Loss: 0.075 | Val Loss: 0.127
Epoch: 56 | Ending LR: 0.000128 
Saving improved model after Val Loss improved from 0.13145 to 0.13031
Epoch: 57 | FT  | Train Loss: 0.07672 | Val Loss: 0.13031
Epoch: 57 | Amp | Train Loss: 0.0037 | Val Loss: 0.0048
Epoch: 57 | Ph  | Train Loss: 0.073 | Val Loss: 0.126
Epoch: 57 | Ending LR: 0.000119 
Saving improved model after Val Loss improved from 0.13031 to 0.12981
Epoch: 58 | FT  | Train Loss: 0.07526 | Val Loss: 0.12981
Epoch: 58 | Amp | Train Loss: 0.0036 | Val Loss: 0.0047
Epoch: 58 | Ph  | Train Loss: 0.072 | Val Loss: 0.125
Epoch: 58 | Ending LR: 0.000109 
Saving improved model after Val Loss improved from 0.12981 to 0.12931
Epoch: 59 | FT  | Train Loss: 0.07408 | Val Loss: 0.12931
Epoch: 59 | Amp | Train Loss: 0.0036 | Val Loss: 0.0047
Epoch: 59 | Ph  | Train Loss: 0.070 | Val Loss: 0.125
Epoch: 59 | Ending LR: 0.000100 
test data shape: (3600, 1, 64, 64) (3600, 1, 64, 64) (3600, 1, 64, 64)
test output amp shape and dtype: (3600, 64, 64) float32
test output phase shape and dtype: (3600, 64, 64) float32
